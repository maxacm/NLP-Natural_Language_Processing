{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DATA-641 Lab 5\n",
        "Max Calzada\n",
        "\n",
        "**Topic Modeling on Amazon Reviews**\n",
        "\n",
        "In this lab, we will work on how to use different methods for topic modeling in order to get insights from Amazon reviews."
      ],
      "metadata": {
        "id": "DRjm-QOdh2Y1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "#matplotlib imports are used to plot confusion matrices for the classifiers\n",
        "import matplotlib as mpl \n",
        "import matplotlib.cm as cm \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "#import feature extraction methods from sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.feature_extraction import _stop_words\n",
        "#pre-processing of text\n",
        "import string\n",
        "import re\n",
        "\n",
        "#import classifiers from sklearn\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "#import different metrics to evaluate the classifiers\n",
        "from sklearn.metrics import accuracy_score\n",
        "#from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn import metrics\n",
        "\n",
        "#import time function from time module to track the training duration\n",
        "from time import time\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from sklearn.decomposition import NMF, PCA, TruncatedSVD, FastICA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdXjg_-U46mT",
        "outputId": "8defb264-4ca8-4634-dc24-7edafb4c47b4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (a) \n",
        "Load the reviews data from the .csv file which is provided on Canvas. Filter the first 20k rows and then remove the null values from the data set. Include those words that appear in less than 80% of the reviews and appear in at least two reviews."
      ],
      "metadata": {
        "id": "NLEATKR5h6p8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DpcfgE40hsuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca5038fe-729c-4680-a1f2-ad3c17375ac6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-bffb2f2ee893>:2: DtypeWarning: Columns (1,2,3,8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  Reviews = pd.read_csv('Reviews_7.csv')\n"
          ]
        }
      ],
      "source": [
        "# Load the reviews data from the .csv file which is provided on Canvas.\n",
        "Reviews = pd.read_csv('Reviews_7.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the first 20k rows\n",
        "Reviews = Reviews[:20000]\n",
        "\n",
        "# and then remove the null values from the data set\n",
        "  # Max: I'm removing entire rows if there is one NA value in that row.\n",
        "Reviews.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "SmvYxeqRgVkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f73c386-d0d9-4938-fe1f-08d0872d330a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-769b04fc2b7c>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Reviews.dropna(inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Include those words that appear in less than 80% of the reviews \n",
        "# and appear in at least two reviews."
      ],
      "metadata": {
        "id": "x8vpHiFFglT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reviews"
      ],
      "metadata": {
        "id": "twiSA6ZclD7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install lime"
      ],
      "metadata": {
        "id": "CNrXCfRsll5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification_Word2Vec.ipynb\n",
        "\n",
        "def clean_text(str_list, lemmatize = False):\n",
        "    clean_list = []\n",
        "    \n",
        "    for text in str_list:\n",
        "        # to drop pound sign from hash tags\n",
        "        text = re.sub(r'#', '', text)\n",
        "        words = word_tokenize(text)\n",
        "        clean_words = []\n",
        "        \n",
        "        for word in words:            \n",
        "            # drop words with fewer than 2 characters; drop any punctuation \"words\"\n",
        "            if (len(word) > 1) and (re.match(r'^\\w+$', word)):\n",
        "\n",
        "                if lemmatize:\n",
        "                    lemmatizer = WordNetLemmatizer()\n",
        "            \n",
        "                clean_words.append(word)\n",
        "        clean_text = ' '.join(clean_words)\n",
        "        clean_list.append(clean_text)\n",
        "    \n",
        "    return clean_list"
      ],
      "metadata": {
        "id": "84rEq3PQlipE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Reviews['clean_Text'] = clean_text(Reviews['Text'])"
      ],
      "metadata": {
        "id": "TvXmzIGDmAkk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/46786211/counting-the-frequency-of-words-in-a-pandas-data-frame\n",
        "\n",
        "Reviews['clean_Text'].str.split(expand=True).stack().value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBxixbxEz44M",
        "outputId": "5c651ab3-51a4-4949-ee53-b3823bde65d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "the          56257\n",
              "and          43213\n",
              "to           34356\n",
              "it           29134\n",
              "of           27539\n",
              "             ...  \n",
              "Morse            1\n",
              "emerges          1\n",
              "Tying            1\n",
              "Guayusa          1\n",
              "depressor        1\n",
              "Length: 33179, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/64435552/count-the-number-of-rows-that-each-word-appears-in\n",
        "\n",
        "def vocab_dict(data):\n",
        "    lines_count = {}\n",
        "    for line in data:\n",
        "        for word in set(line.split()):\n",
        "            old_count = lines_count.get(word, 0)\n",
        "            lines_count[word] = old_count + 1\n",
        "    return lines_count"
      ],
      "metadata": {
        "id": "oZhz21Oj025c"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab_dict(Reviews['clean_Text'])"
      ],
      "metadata": {
        "id": "KatYHpY507oE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Reviews_dict = vocab_dict(Reviews['clean_Text'])"
      ],
      "metadata": {
        "id": "kMPS21fT3vVS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code based off of: https://learnpython.com/blog/filter-dictionary-in-python/\n",
        "\n",
        "def at_least_2(pair):\n",
        "    key, value = pair\n",
        "    if value >= 2:\n",
        "        return True  # keep pair in the filtered dictionary\n",
        "    else:\n",
        "        return False  # filter pair out of the dictionary"
      ],
      "metadata": {
        "id": "4eyopnO74E8a"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code based off of: https://learnpython.com/blog/filter-dictionary-in-python/\n",
        "filter_1 = dict(filter(at_least_2, Reviews_dict.items()))\n",
        "# filter_1\n",
        "\n",
        "# Code based off of: https://blog.finxter.com/how-to-get-the-key-with-minimum-value-in-a-python-dictionary/#:~:text=To%20find%20the%20key%20with,to%20get%20their%20associated%20values.\n",
        "print(min(filter_1.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rIkCMCA4fbi",
        "outputId": "94edfcfe-0724-49d5-e682-43a021f92a58"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rev_len = len(Reviews)\n",
        "print(rev_len * 0.8, rev_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh78JKEC5-bV",
        "outputId": "06a50a69-77b9-477a-e9f7-81b3d2df6d3c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16000.0 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code based off of: https://learnpython.com/blog/filter-dictionary-in-python/\n",
        "\n",
        "def less_than_80pc(pair):\n",
        "    key, value = pair\n",
        "    if value < 0.8*rev_len:\n",
        "        return True  # keep pair in the filtered dictionary\n",
        "    else:\n",
        "        return False  # filter pair out of the dictionary"
      ],
      "metadata": {
        "id": "at1ZG6hr6jqv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_dict = dict(filter(less_than_80pc, Reviews_dict.items()))\n",
        "print(len(filter_dict), max(filter_dict.values()) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S7HmT3J6vx3",
        "outputId": "8f15dedf-19a0-4e80-9afd-1908f5eadb4f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33179 15909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filter_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLKOkJnaQoi6",
        "outputId": "f6557388-a8ed-4322-c4b3-12c585095e13"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'this': 10374,\n",
              " 'smells': 187,\n",
              " 'looks': 250,\n",
              " 'stew': 20,\n",
              " 'it': 11666,\n",
              " 'have': 7685,\n",
              " 'is': 12298,\n",
              " 'Vitality': 3,\n",
              " 'found': 1659,\n",
              " 'of': 11776,\n",
              " 'more': 3546,\n",
              " 'than': 3355,\n",
              " 'dog': 1158,\n",
              " 'and': 15775,\n",
              " 'My': 2904,\n",
              " 'better': 2153,\n",
              " 'like': 5979,\n",
              " 'them': 4495,\n",
              " 'all': 3879,\n",
              " 'food': 1879,\n",
              " 'to': 13516,\n",
              " 'Labrador': 3,\n",
              " 'product': 3637,\n",
              " 'the': 15909,\n",
              " 'good': 5091,\n",
              " 'processed': 100,\n",
              " 'several': 649,\n",
              " 'quality': 988,\n",
              " 'be': 4871,\n",
              " 'most': 1208,\n",
              " 'finicky': 48,\n",
              " 'she': 879,\n",
              " 'meat': 289,\n",
              " 'appreciates': 6,\n",
              " 'The': 5646,\n",
              " 'canned': 218,\n",
              " 'products': 839,\n",
              " 'bought': 1468,\n",
              " 'or': 4412,\n",
              " 'sure': 963,\n",
              " 'was': 6258,\n",
              " 'sized': 114,\n",
              " 'vendor': 63,\n",
              " 'intended': 34,\n",
              " 'arrived': 547,\n",
              " 'an': 2527,\n",
              " 'labeled': 54,\n",
              " 'actually': 781,\n",
              " 'Jumbo': 3,\n",
              " 'were': 2284,\n",
              " 'if': 3026,\n",
              " 'error': 32,\n",
              " 'Salted': 10,\n",
              " 'as': 5270,\n",
              " 'represent': 4,\n",
              " 'peanuts': 125,\n",
              " 'small': 993,\n",
              " 'Not': 827,\n",
              " 'unsalted': 15,\n",
              " 'Peanuts': 16,\n",
              " 'Product': 87,\n",
              " 'recommend': 1472,\n",
              " 'around': 656,\n",
              " 'his': 644,\n",
              " 'confection': 9,\n",
              " 'few': 1140,\n",
              " 'then': 1366,\n",
              " 'And': 859,\n",
              " 'powdered': 135,\n",
              " 'liberally': 6,\n",
              " 'you': 6168,\n",
              " 'Sisters': 2,\n",
              " 'This': 4666,\n",
              " 'Edmund': 2,\n",
              " 'has': 3571,\n",
              " 'with': 7701,\n",
              " 'are': 6785,\n",
              " 'sugar': 1254,\n",
              " 'that': 8045,\n",
              " 'coated': 37,\n",
              " 'Wardrobe': 1,\n",
              " 'cut': 283,\n",
              " 'been': 2158,\n",
              " 'too': 2650,\n",
              " 'If': 1866,\n",
              " 'Witch': 1,\n",
              " 'citrus': 76,\n",
              " 'nuts': 218,\n",
              " 'mouthful': 17,\n",
              " 'chewy': 159,\n",
              " 'heaven': 48,\n",
              " 'very': 3960,\n",
              " 'Filberts': 1,\n",
              " 'yummy': 258,\n",
              " 'highly': 586,\n",
              " 'into': 1151,\n",
              " 'treat': 799,\n",
              " 'story': 61,\n",
              " 'Lewis': 1,\n",
              " 'in': 9711,\n",
              " 'Lion': 4,\n",
              " 'seduces': 1,\n",
              " 'It': 5221,\n",
              " 'centuries': 3,\n",
              " 'gelatin': 17,\n",
              " 'familiar': 39,\n",
              " 'selling': 93,\n",
              " 'pillowy': 1,\n",
              " 'squares': 51,\n",
              " 'out': 3084,\n",
              " 'case': 529,\n",
              " 'Brother': 4,\n",
              " 'flavorful': 311,\n",
              " 'light': 546,\n",
              " 'tiny': 184,\n",
              " 'made': 1535,\n",
              " 'got': 1179,\n",
              " 'Root': 9,\n",
              " 'addition': 202,\n",
              " 'medicinal': 21,\n",
              " 'secret': 29,\n",
              " 'flavor': 3666,\n",
              " 'Beer': 15,\n",
              " 'some': 2657,\n",
              " 'cherry': 110,\n",
              " 'which': 2036,\n",
              " 'ingredient': 286,\n",
              " 'Robitussin': 3,\n",
              " 'ordered': 973,\n",
              " 'Extract': 17,\n",
              " 'looking': 857,\n",
              " 'believe': 377,\n",
              " 'for': 10310,\n",
              " 'soda': 438,\n",
              " 'lover': 108,\n",
              " 'Delivery': 25,\n",
              " 'assortment': 32,\n",
              " 'wide': 49,\n",
              " 'Great': 751,\n",
              " 'deal': 483,\n",
              " 'There': 765,\n",
              " 'price': 2148,\n",
              " 'quick': 377,\n",
              " 'taffy': 21,\n",
              " 'your': 2155,\n",
              " 'at': 4337,\n",
              " 'great': 4163,\n",
              " 'hair': 61,\n",
              " 'bit': 1307,\n",
              " 'weeks': 270,\n",
              " 'brand': 1013,\n",
              " 'many': 1267,\n",
              " 'husband': 537,\n",
              " 'bag': 1349,\n",
              " 'complaint': 144,\n",
              " 'there': 1874,\n",
              " 'just': 4277,\n",
              " 'would': 3607,\n",
              " 'my': 7782,\n",
              " 'particular': 208,\n",
              " 'enjoyable': 89,\n",
              " 'beer': 75,\n",
              " 'etc': 363,\n",
              " 'kids': 444,\n",
              " 'flavors': 1145,\n",
              " 'delightful': 77,\n",
              " 'me': 3224,\n",
              " 'lasted': 44,\n",
              " 'Between': 11,\n",
              " 'grape': 126,\n",
              " 'much': 2610,\n",
              " 'pound': 184,\n",
              " 'only': 2716,\n",
              " 'five': 179,\n",
              " 'watermelon': 22,\n",
              " 'melon': 3,\n",
              " 'not': 7152,\n",
              " 'root': 41,\n",
              " 'peppermint': 69,\n",
              " 'favorites': 176,\n",
              " 'wild': 49,\n",
              " 'pieces': 344,\n",
              " 'two': 1287,\n",
              " 'Would': 170,\n",
              " 'saltwater': 1,\n",
              " 'served': 118,\n",
              " 'wrapped': 101,\n",
              " 'Fralinger': 1,\n",
              " 'had': 3303,\n",
              " 'party': 123,\n",
              " 'Each': 158,\n",
              " 'individually': 69,\n",
              " 'happen': 89,\n",
              " 'loved': 603,\n",
              " 'candies': 85,\n",
              " 'did': 2079,\n",
              " 'soft': 349,\n",
              " 'version': 313,\n",
              " 'candy': 340,\n",
              " 'None': 42,\n",
              " 'together': 211,\n",
              " 'expensive': 706,\n",
              " 'well': 1883,\n",
              " 'stuck': 142,\n",
              " 'everyone': 301,\n",
              " 'so': 5347,\n",
              " 'Very': 516,\n",
              " 'amazing': 359,\n",
              " 'definitely': 824,\n",
              " 'buying': 907,\n",
              " 'satisfying': 169,\n",
              " 'They': 2403,\n",
              " 'Rye': 6,\n",
              " 'grass': 74,\n",
              " 'Right': 38,\n",
              " 'mostly': 185,\n",
              " 'can': 3953,\n",
              " 'rotate': 12,\n",
              " 'Wheatgrass': 1,\n",
              " 'cats': 255,\n",
              " 'sprouting': 11,\n",
              " 'now': 1560,\n",
              " 'love': 3071,\n",
              " 'eat': 1683,\n",
              " 'their': 1482,\n",
              " 'amount': 630,\n",
              " 'Good': 367,\n",
              " 'feeding': 209,\n",
              " 'required': 52,\n",
              " 'healthy': 949,\n",
              " 'Also': 465,\n",
              " 'digestion': 48,\n",
              " 'puppies': 28,\n",
              " 'every': 1085,\n",
              " 'eats': 195,\n",
              " 'her': 851,\n",
              " 'anywhere': 168,\n",
              " 'combination': 188,\n",
              " 'mean': 168,\n",
              " 'city': 19,\n",
              " 'cactus': 3,\n",
              " 'magic': 24,\n",
              " 'know': 1314,\n",
              " 'realize': 119,\n",
              " 'tequila': 8,\n",
              " 'never': 1132,\n",
              " 'grab': 78,\n",
              " 'trip': 103,\n",
              " 'makes': 1125,\n",
              " 'ecstatic': 12,\n",
              " 'once': 491,\n",
              " 'us': 493,\n",
              " 'Now': 460,\n",
              " 'picked': 110,\n",
              " 'hot': 1003,\n",
              " 'ingredients': 911,\n",
              " 'br': 5047,\n",
              " 'home': 570,\n",
              " 'Just': 498,\n",
              " 'Picante': 3,\n",
              " 'back': 921,\n",
              " 'tastelessly': 2,\n",
              " 'Gourmet': 50,\n",
              " 'on': 6235,\n",
              " 'de': 29,\n",
              " 'brought': 132,\n",
              " 'away': 618,\n",
              " 'unique': 127,\n",
              " 'service': 251,\n",
              " 'personal': 117,\n",
              " 'internet': 76,\n",
              " 'one': 3976,\n",
              " 'do': 3973,\n",
              " 'taste': 4344,\n",
              " 'burns': 11,\n",
              " 'find': 2179,\n",
              " 'we': 1868,\n",
              " 'want': 1280,\n",
              " 'kind': 509,\n",
              " 'really': 2783,\n",
              " 'Tequila': 2,\n",
              " 'Inclan': 2,\n",
              " 'sauce': 423,\n",
              " 'When': 792,\n",
              " 'other': 3007,\n",
              " 'Thank': 250,\n",
              " 'throat': 41,\n",
              " 'but': 7958,\n",
              " 'up': 2741,\n",
              " 'incredible': 73,\n",
              " 'blown': 22,\n",
              " 'any': 1926,\n",
              " 'because': 2357,\n",
              " 'will': 3372,\n",
              " 'simply': 238,\n",
              " 'We': 1588,\n",
              " 'flavour': 56,\n",
              " 'could': 1705,\n",
              " 'our': 1315,\n",
              " 'realized': 78,\n",
              " 'use': 2265,\n",
              " 'bottle': 280,\n",
              " 'totally': 176,\n",
              " 'lose': 94,\n",
              " 'losing': 31,\n",
              " 'weight': 276,\n",
              " 'floor': 60,\n",
              " 'chubby': 4,\n",
              " 'needed': 265,\n",
              " 'sits': 39,\n",
              " 'jump': 24,\n",
              " 'boys': 46,\n",
              " 'skinny': 19,\n",
              " 'One': 464,\n",
              " 'guy': 79,\n",
              " 'put': 916,\n",
              " 'stale': 152,\n",
              " 'where': 555,\n",
              " 'going': 818,\n",
              " 'go': 1295,\n",
              " 'both': 727,\n",
              " 'about': 2754,\n",
              " 'ounce': 177,\n",
              " 'higher': 195,\n",
              " 'boy': 52,\n",
              " 'week': 323,\n",
              " 'no': 2469,\n",
              " 'happily': 43,\n",
              " 'eating': 826,\n",
              " 'different': 1065,\n",
              " 'reviews': 600,\n",
              " 'Felidae': 19,\n",
              " 'bowls': 42,\n",
              " 'shape': 151,\n",
              " 'changes': 41,\n",
              " 'years': 1038,\n",
              " 'formula': 200,\n",
              " 'Platinum': 10,\n",
              " 'past': 270,\n",
              " 'similar': 301,\n",
              " 'first': 1675,\n",
              " 'need': 870,\n",
              " 'kitties': 29,\n",
              " 'full': 626,\n",
              " 'Unfortunately': 226,\n",
              " 'related': 25,\n",
              " 'new': 675,\n",
              " 'sit': 136,\n",
              " 'tried': 2312,\n",
              " 'when': 3105,\n",
              " 'noticed': 234,\n",
              " 'touch': 133,\n",
              " 'delicious': 1158,\n",
              " 'packed': 185,\n",
              " 'securely': 22,\n",
              " 'they': 4902,\n",
              " 'fresh': 868,\n",
              " 'Twizzlers': 10,\n",
              " 'these': 4345,\n",
              " 'came': 646,\n",
              " 'while': 832,\n",
              " 'guilty': 51,\n",
              " 'Six': 8,\n",
              " 'son': 356,\n",
              " 'pounds': 116,\n",
              " 'pleasure': 48,\n",
              " 'Strawberry': 62,\n",
              " 'hit': 201,\n",
              " 'daughter': 345,\n",
              " 'packages': 186,\n",
              " 'shipment': 163,\n",
              " 'expect': 263,\n",
              " 'strawberry': 142,\n",
              " 'twizzlers': 1,\n",
              " 'loves': 999,\n",
              " 'exactly': 301,\n",
              " 'what': 1953,\n",
              " 'spot': 74,\n",
              " 'six': 169,\n",
              " 'transfer': 14,\n",
              " 'time': 2384,\n",
              " 'lock': 22,\n",
              " 'TV': 21,\n",
              " 'watching': 82,\n",
              " 'sweet': 1283,\n",
              " 'zip': 36,\n",
              " 'stay': 159,\n",
              " 'baggie': 14,\n",
              " 'take': 758,\n",
              " 'movies': 13,\n",
              " 'enjoyed': 372,\n",
              " 'am': 2116,\n",
              " 'shared': 69,\n",
              " 'satisfied': 134,\n",
              " 'purchase': 765,\n",
              " 'others': 491,\n",
              " 'Twizzler': 2,\n",
              " 'ordering': 400,\n",
              " 'measured': 23,\n",
              " 'place': 299,\n",
              " 'oldest': 26,\n",
              " 'Records': 1,\n",
              " 'Color': 7,\n",
              " '370': 1,\n",
              " 'cool': 116,\n",
              " '100': 525,\n",
              " 'Apple': 54,\n",
              " 'You': 1042,\n",
              " 'Candies': 6,\n",
              " 'Company': 23,\n",
              " 'by': 1961,\n",
              " 'Pounds': 3,\n",
              " 'dry': 427,\n",
              " 'Twist': 5,\n",
              " 'Feet': 1,\n",
              " 'keep': 922,\n",
              " 'Kg': 2,\n",
              " 'became': 112,\n",
              " 'Twists': 4,\n",
              " 'Book': 2,\n",
              " 'Guinness': 2,\n",
              " '1845': 1,\n",
              " '19': 27,\n",
              " 'Firms': 1,\n",
              " 'Kosher': 13,\n",
              " 'recommended': 390,\n",
              " 'longest': 9,\n",
              " 'Subsidiary': 1,\n",
              " 'Green': 287,\n",
              " 'also': 2071,\n",
              " 'Licorice': 22,\n",
              " 'Pennsylvania': 8,\n",
              " 'weighted': 2,\n",
              " 'Young': 3,\n",
              " 'States': 34,\n",
              " '45': 62,\n",
              " 'Lancaster': 2,\n",
              " 'childhood': 44,\n",
              " 'Raspberry': 29,\n",
              " 'Hershey': 23,\n",
              " 'favorite': 1373,\n",
              " 'Record': 1,\n",
              " 'fridge': 119,\n",
              " 'United': 25,\n",
              " 'established': 7,\n",
              " 'make': 2175,\n",
              " 'confectionery': 3,\n",
              " 'World': 40,\n",
              " 'July': 22,\n",
              " '1998': 1,\n",
              " 'Smylie': 1,\n",
              " 'Inc': 3,\n",
              " 'Blue': 141,\n",
              " 'ever': 1013,\n",
              " 'According': 26,\n",
              " 'get': 2852,\n",
              " 'delivered': 195,\n",
              " 'perfect': 967,\n",
              " 'Candy': 15,\n",
              " 'purchased': 689,\n",
              " 'store': 1338,\n",
              " 'bound': 8,\n",
              " 'unable': 67,\n",
              " 'fast': 368,\n",
              " 'reasonable': 191,\n",
              " 'ca': 1065,\n",
              " 'times': 484,\n",
              " 'assigned': 3,\n",
              " 'from': 3567,\n",
              " 'country': 58,\n",
              " 'government': 7,\n",
              " 'always': 1035,\n",
              " 'addict': 31,\n",
              " 'Amazon': 1945,\n",
              " 'arrive': 79,\n",
              " 'employees': 9,\n",
              " 'tasty': 833,\n",
              " 'manner': 42,\n",
              " 'overseas': 15,\n",
              " 'living': 68,\n",
              " 'timely': 60,\n",
              " 'likes': 370,\n",
              " 'generous': 36,\n",
              " 'He': 496,\n",
              " 'apparently': 69,\n",
              " 'amounts': 77,\n",
              " 'Pack': 294,\n",
              " 'Bags': 46,\n",
              " 'each': 657,\n",
              " 'http': 431,\n",
              " 'who': 1366,\n",
              " 'worth': 694,\n",
              " 'staff': 13,\n",
              " 'currently': 67,\n",
              " 'wo': 593,\n",
              " 'Still': 125,\n",
              " 'disappointed': 530,\n",
              " 'dropped': 34,\n",
              " 'superb': 38,\n",
              " 'remember': 159,\n",
              " 'kid': 108,\n",
              " 'After': 505,\n",
              " 'watchers': 16,\n",
              " 'craving': 92,\n",
              " 'still': 1324,\n",
              " 'YUM': 35,\n",
              " 'visit': 65,\n",
              " 'yrs': 19,\n",
              " 'say': 1139,\n",
              " 'faithful': 6,\n",
              " 'buy': 2377,\n",
              " 'All': 420,\n",
              " 'Mexico': 12,\n",
              " 'able': 526,\n",
              " 'over': 1385,\n",
              " 'lived': 63,\n",
              " 'someone': 280,\n",
              " 'visits': 12,\n",
              " 'stock': 212,\n",
              " 'often': 371,\n",
              " 'right': 1097,\n",
              " 'buyer': 28,\n",
              " 'Sell': 4,\n",
              " 'US': 95,\n",
              " 'miss': 100,\n",
              " 'received': 543,\n",
              " 'No': 559,\n",
              " 'red': 142,\n",
              " 'again': 1719,\n",
              " 'plan': 175,\n",
              " 'batteries': 4,\n",
              " 'garage': 8,\n",
              " 'elsewhere': 86,\n",
              " 'carried': 60,\n",
              " 'glad': 395,\n",
              " 'hard': 900,\n",
              " 'finding': 188,\n",
              " 'such': 516,\n",
              " 'size': 810,\n",
              " 'door': 120,\n",
              " 'snacking': 58,\n",
              " 'toffees': 2,\n",
              " 'intake': 84,\n",
              " 'pretty': 808,\n",
              " 'These': 1778,\n",
              " 'chocolate': 1066,\n",
              " 'needs': 238,\n",
              " 'chooses': 4,\n",
              " 'sugary': 78,\n",
              " 'EXCELLENT': 21,\n",
              " 'Mum': 2,\n",
              " 'unnecessary': 15,\n",
              " 'guilt': 34,\n",
              " 'instead': 501,\n",
              " 'limit': 47,\n",
              " 'father': 36,\n",
              " 'tooth': 83,\n",
              " 'free': 991,\n",
              " 'impressed': 171,\n",
              " 'office': 120,\n",
              " 'LOVED': 50,\n",
              " 'myself': 427,\n",
              " 'dark': 463,\n",
              " 'diabetic': 41,\n",
              " 'watch': 114,\n",
              " 'guess': 289,\n",
              " 'machine': 287,\n",
              " 'super': 263,\n",
              " 'less': 1026,\n",
              " 'talked': 19,\n",
              " 'Too': 90,\n",
              " 'huge': 239,\n",
              " 'heated': 34,\n",
              " 'Dolche': 1,\n",
              " 'Machine': 7,\n",
              " 'Dolce': 19,\n",
              " 'minute': 114,\n",
              " 'water': 1271,\n",
              " 'Macciato': 1,\n",
              " 'coffee': 2886,\n",
              " 'Coffee': 345,\n",
              " 'usually': 627,\n",
              " 'Gusto': 17,\n",
              " 'fan': 431,\n",
              " 'Shop': 72,\n",
              " 'Guesto': 1,\n",
              " 'easy': 976,\n",
              " 'prepares': 2,\n",
              " 'little': 2321,\n",
              " 'drinker': 177,\n",
              " 'anyone': 407,\n",
              " 'mother': 99,\n",
              " 'trying': 658,\n",
              " 'Latte': 14,\n",
              " 'However': 696,\n",
              " 'getting': 643,\n",
              " 'thanks': 86,\n",
              " 'Staral': 1,\n",
              " 'offer': 121,\n",
              " 'thick': 187,\n",
              " 'three': 498,\n",
              " 'bowl': 191,\n",
              " 'even': 1908,\n",
              " 'plus': 287,\n",
              " 'should': 744,\n",
              " 'nowhere': 27,\n",
              " 'helped': 123,\n",
              " 'boiling': 55,\n",
              " 'gum': 128,\n",
              " 'fructose': 69,\n",
              " 'gluey': 4,\n",
              " 'Real': 27,\n",
              " 'thing': 874,\n",
              " 'minutes': 392,\n",
              " 'cane': 58,\n",
              " 'syrup': 388,\n",
              " 'tastes': 1273,\n",
              " 'McCann': 14,\n",
              " 'extreme': 21,\n",
              " 'creamy': 174,\n",
              " 'organic': 705,\n",
              " 'why': 485,\n",
              " 'requiring': 12,\n",
              " 'Oats': 28,\n",
              " 'guar': 3,\n",
              " 'varieties': 204,\n",
              " 'Instant': 23,\n",
              " 'actual': 130,\n",
              " 'harmful': 17,\n",
              " 'without': 1224,\n",
              " 'microwave': 281,\n",
              " 'stuff': 958,\n",
              " 'near': 138,\n",
              " 'Oatmeal': 28,\n",
              " 'fact': 498,\n",
              " 'heat': 235,\n",
              " 'escaping': 1,\n",
              " 'becomes': 53,\n",
              " 'convenient': 221,\n",
              " 'gets': 288,\n",
              " 'adding': 255,\n",
              " 'however': 390,\n",
              " 'decide': 64,\n",
              " 'But': 1155,\n",
              " 'scrape': 10,\n",
              " 'convenience': 159,\n",
              " 'oatmeal': 221,\n",
              " 'after': 1507,\n",
              " 'thickeners': 3,\n",
              " 'variety': 489,\n",
              " 'though': 907,\n",
              " 'must': 399,\n",
              " 'corn': 394,\n",
              " 'instant': 176,\n",
              " 'prepared': 92,\n",
              " 'Maybe': 176,\n",
              " 'preparation': 26,\n",
              " 'stovetop': 7,\n",
              " 'brands': 664,\n",
              " 'sitting': 115,\n",
              " 'best': 2169,\n",
              " 'prepare': 115,\n",
              " 'high': 834,\n",
              " 'pack': 747,\n",
              " 'cold': 244,\n",
              " 'tell': 345,\n",
              " 'regular': 973,\n",
              " 'doctors': 10,\n",
              " 'sweetness': 221,\n",
              " 'does': 1995,\n",
              " 'Cut': 14,\n",
              " 'apart': 106,\n",
              " 'fructouse': 1,\n",
              " 'require': 54,\n",
              " 'apple': 235,\n",
              " 'maple': 104,\n",
              " 'Plus': 151,\n",
              " 'uses': 165,\n",
              " 'morning': 612,\n",
              " 'cinnamon': 192,\n",
              " 'doctoring': 4,\n",
              " 'form': 125,\n",
              " 'brown': 209,\n",
              " 'Steel': 8,\n",
              " 'may': 712,\n",
              " 'Brown': 58,\n",
              " 'Regular': 28,\n",
              " 'Variety': 30,\n",
              " 'Apples': 18,\n",
              " 'Cinnamon': 65,\n",
              " 'Maple': 41,\n",
              " 'Sugar': 100,\n",
              " 'same': 1011,\n",
              " 'become': 216,\n",
              " 'second': 359,\n",
              " 'Boxes': 42,\n",
              " 'soggy': 25,\n",
              " 'close': 240,\n",
              " 'eaten': 213,\n",
              " 'Irish': 36,\n",
              " 'meal': 293,\n",
              " 'holds': 74,\n",
              " 'its': 808,\n",
              " 'texture': 667,\n",
              " 'hits': 47,\n",
              " 'oat': 29,\n",
              " 'longer': 382,\n",
              " 'excellent': 646,\n",
              " 'easily': 348,\n",
              " 'give': 1267,\n",
              " 'hardy': 5,\n",
              " 'digestible': 9,\n",
              " 'folks': 86,\n",
              " 'try': 1980,\n",
              " 'surgery': 20,\n",
              " 'oats': 60,\n",
              " 'thought': 878,\n",
              " 'palatable': 32,\n",
              " 'fiber': 194,\n",
              " 'bloat': 7,\n",
              " 'disease': 68,\n",
              " 'health': 399,\n",
              " 'For': 590,\n",
              " 'half': 607,\n",
              " 'Thanks': 246,\n",
              " 'almost': 745,\n",
              " 'Abby': 2,\n",
              " 'those': 820,\n",
              " 'lifesaver': 6,\n",
              " 'celiac': 55,\n",
              " 'grocery': 653,\n",
              " 'nuke': 12,\n",
              " 'More': 59,\n",
              " 'raisins': 45,\n",
              " 'Mmm': 7,\n",
              " 'else': 403,\n",
              " 'add': 902,\n",
              " 'What': 424,\n",
              " 'something': 1134,\n",
              " 'milk': 711,\n",
              " 'tastier': 44,\n",
              " 'Kroger': 12,\n",
              " 'cup': 1445,\n",
              " 'maybe': 375,\n",
              " '90': 55,\n",
              " 'seconds': 121,\n",
              " 'MY': 79,\n",
              " 'NO': 147,\n",
              " 'AT': 37,\n",
              " 'ON': 59,\n",
              " 'USE': 13,\n",
              " 'FRIEND': 2,\n",
              " 'YOUR': 31,\n",
              " 'McCANNS': 1,\n",
              " 'READY': 3,\n",
              " 'JERRY': 1,\n",
              " 'VERY': 139,\n",
              " 'GOES': 1,\n",
              " 'IN': 96,\n",
              " 'SO': 111,\n",
              " 'AND': 185,\n",
              " 'APPLE': 6,\n",
              " 'HE': 8,\n",
              " 'YOU': 75,\n",
              " 'MILK': 11,\n",
              " 'OF': 94,\n",
              " 'CAME': 7,\n",
              " 'HIS': 4,\n",
              " 'OWN': 6,\n",
              " 'BE': 40,\n",
              " 'INSTANT': 5,\n",
              " 'TASTEFULL': 1,\n",
              " 'ROOM': 2,\n",
              " 'NATE': 1,\n",
              " 'TRY': 24,\n",
              " 'SOMETIMES': 6,\n",
              " 'TRYING': 3,\n",
              " 'WATER': 13,\n",
              " 'NOT': 318,\n",
              " 'VISITING': 1,\n",
              " 'FOR': 81,\n",
              " 'OUT': 20,\n",
              " 'PACKET': 3,\n",
              " 'OATMEAL': 2,\n",
              " 'GIVE': 12,\n",
              " 'SAY': 8,\n",
              " 'ENDED': 1,\n",
              " 'OR': 34,\n",
              " 'FOUND': 13,\n",
              " 'SUGGESTED': 1,\n",
              " 'LEAST': 10,\n",
              " 'OTHER': 17,\n",
              " 'CINN': 1,\n",
              " 'THE': 176,\n",
              " 'STASH': 2,\n",
              " 'SLICE': 2,\n",
              " 'DAY': 15,\n",
              " 'MADE': 18,\n",
              " 'TOAST': 1,\n",
              " 'TAKE': 6,\n",
              " 'UP': 13,\n",
              " 'WORLD': 1,\n",
              " 'COFFEE': 29,\n",
              " 'CHANCE': 1,\n",
              " 'IT': 139,\n",
              " 'WAS': 48,\n",
              " 'POWDERED': 2,\n",
              " 'TO': 102,\n",
              " 'GOOD': 56,\n",
              " 'IRISH': 2,\n",
              " 'WITH': 48,\n",
              " 'DOSE': 1,\n",
              " 'WHEN': 14,\n",
              " 'THAT': 79,\n",
              " 'MORNING': 3,\n",
              " 'STORAGE': 3,\n",
              " 'REITH': 1,\n",
              " 'McCANN': 3,\n",
              " 'happy': 783,\n",
              " 'She': 474,\n",
              " 'reccomended': 3,\n",
              " 'wife': 309,\n",
              " 'pour': 108,\n",
              " 'extremely': 244,\n",
              " 'expand': 15,\n",
              " 'tired': 86,\n",
              " 'earth': 39,\n",
              " '2x': 5,\n",
              " 'cheap': 224,\n",
              " 'apples': 90,\n",
              " 'packet': 161,\n",
              " 'pot': 208,\n",
              " 'Convenient': 14,\n",
              " 'terrific': 59,\n",
              " 'boil': 43,\n",
              " 'packs': 203,\n",
              " 'takes': 235,\n",
              " 'per': 673,\n",
              " 'cents': 92,\n",
              " 'Taste': 116,\n",
              " 'At': 286,\n",
              " 'followed': 85,\n",
              " 'empty': 76,\n",
              " 'ole': 22,\n",
              " 'understand': 118,\n",
              " 'single': 270,\n",
              " 'America': 45,\n",
              " 'cooks': 44,\n",
              " 'chance': 127,\n",
              " 'hour': 88,\n",
              " 'state': 87,\n",
              " 'family': 641,\n",
              " 'consider': 189,\n",
              " 'offering': 62,\n",
              " 'here': 846,\n",
              " 'whether': 95,\n",
              " 'sloth': 1,\n",
              " 'experience': 271,\n",
              " 'giving': 321,\n",
              " 'difference': 355,\n",
              " 'allows': 77,\n",
              " 'person': 167,\n",
              " 'experiment': 47,\n",
              " 'connoisseur': 28,\n",
              " 'personally': 98,\n",
              " 'raw': 151,\n",
              " 'liquidy': 4,\n",
              " 'addled': 1,\n",
              " 'handle': 70,\n",
              " 'top': 486,\n",
              " 'thicker': 73,\n",
              " 'available': 518,\n",
              " 'body': 208,\n",
              " 'whole': 765,\n",
              " 'how': 1068,\n",
              " 'done': 266,\n",
              " '1300watt': 1,\n",
              " 'pellet': 2,\n",
              " 'between': 253,\n",
              " 'beauty': 14,\n",
              " 'end': 334,\n",
              " 'oatmeals': 8,\n",
              " 'bad': 930,\n",
              " 'under': 221,\n",
              " 'lot': 1067,\n",
              " 'explored': 3,\n",
              " 'tends': 40,\n",
              " 'alone': 133,\n",
              " 'boxes': 363,\n",
              " 'In': 611,\n",
              " 'save': 383,\n",
              " 'Tastes': 99,\n",
              " 'choice': 294,\n",
              " 'Our': 306,\n",
              " 'none': 176,\n",
              " 'overly': 141,\n",
              " 'breakfast': 336,\n",
              " 'regularly': 98,\n",
              " 'keeps': 167,\n",
              " 'steel': 20,\n",
              " 'Anything': 16,\n",
              " 'cook': 265,\n",
              " 'quite': 742,\n",
              " 'mushy': 53,\n",
              " 'pass': 69,\n",
              " 'supermarket': 139,\n",
              " 'probably': 625,\n",
              " 'seems': 564,\n",
              " 'either': 481,\n",
              " 'somewhat': 180,\n",
              " 'muster': 4,\n",
              " 'wholesome': 58,\n",
              " 'comes': 564,\n",
              " 'since': 1115,\n",
              " 'Though': 63,\n",
              " 'follow': 96,\n",
              " 'package': 667,\n",
              " 'directions': 133,\n",
              " 'soupy': 6,\n",
              " 'That': 526,\n",
              " 'differce': 1,\n",
              " 'see': 878,\n",
              " 'Oaker': 1,\n",
              " 'OK': 157,\n",
              " 'added': 717,\n",
              " 'fine': 512,\n",
              " 'order': 1275,\n",
              " 'Save': 113,\n",
              " 'nothing': 464,\n",
              " 'money': 547,\n",
              " 'sugars': 109,\n",
              " 'least': 511,\n",
              " 'stores': 658,\n",
              " 'box': 1053,\n",
              " 'carbs': 140,\n",
              " 'big': 746,\n",
              " 'Its': 181,\n",
              " 'way': 1438,\n",
              " 'Quaker': 17,\n",
              " 'burn': 91,\n",
              " 'temp': 16,\n",
              " 'im': 36,\n",
              " 'mary': 1,\n",
              " 'seller': 176,\n",
              " 'So': 1128,\n",
              " 'mouth': 372,\n",
              " 'mix': 1134,\n",
              " 'nice': 1162,\n",
              " 'advertising': 22,\n",
              " 'bloody': 6,\n",
              " 'worked': 206,\n",
              " 'lol': 59,\n",
              " 'Hot': 144,\n",
              " 'forever': 56,\n",
              " 'yet': 458,\n",
              " 'Got': 61,\n",
              " 'buddies': 9,\n",
              " 'Perfect': 106,\n",
              " 'Ass': 4,\n",
              " 'Country': 25,\n",
              " 'Fartless': 1,\n",
              " 'ears': 20,\n",
              " 'Cradle': 1,\n",
              " 'requires': 53,\n",
              " 'glands': 4,\n",
              " 'work': 779,\n",
              " 'looked': 285,\n",
              " 'contents': 63,\n",
              " 'Black': 133,\n",
              " 'Greg': 1,\n",
              " 'arms': 8,\n",
              " 'Horseradish': 1,\n",
              " 'suspect': 48,\n",
              " 'along': 247,\n",
              " 'hands': 120,\n",
              " 'Vermont': 27,\n",
              " 'wash': 55,\n",
              " 'running': 131,\n",
              " 'Bean': 50,\n",
              " 'already': 256,\n",
              " 'people': 736,\n",
              " 'Kickin': 2,\n",
              " 'advertised': 104,\n",
              " 'ideas': 17,\n",
              " 'Back': 32,\n",
              " 'Weston': 3,\n",
              " 'last': 725,\n",
              " 'insulted': 2,\n",
              " 'hitting': 7,\n",
              " 'Art': 4,\n",
              " 'evenly': 22,\n",
              " 'beverage': 174,\n",
              " 'Jelly': 32,\n",
              " 'Kleenex': 1,\n",
              " 'look': 544,\n",
              " 'Newton': 2,\n",
              " 'important': 144,\n",
              " 'Cranberry': 8,\n",
              " 'spices': 114,\n",
              " 'whose': 32,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (b) \n",
        "Apply truncated SVD using five components. Print the ten strongest words for each of the topics."
      ],
      "metadata": {
        "id": "813MEcIb72Mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# features\n",
        "tfidf = TfidfVectorizer(max_df = 0.8, min_df = 2, stop_words = \"english\")\n",
        "revs_tfidf = tfidf.fit_transform(Reviews['clean_Text'])"
      ],
      "metadata": {
        "id": "TTf_0OJ4FtXs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svdT = TruncatedSVD(n_components = 5)\n",
        "svdTFit = svdT.fit_transform(revs_tfidf)"
      ],
      "metadata": {
        "id": "GjB86Vi-GkjE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, topic in enumerate(svdT.components_):\n",
        "\n",
        "    first_topic_svd = svdT.components_[i]\n",
        "    top_topic_words_svd = first_topic_svd.argsort()[-10:]\n",
        "\n",
        "    print(\"Top 10 words for topic #{}\".format(i + 1))\n",
        "    print([tfidf.get_feature_names_out()[i] for i in top_topic_words_svd])\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8sYUc0JG3Cx",
        "outputId": "df764939-524d-4c8a-8e05-aabb9dc38f8f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 words for topic #1\n",
            "['product', 'tea', 'flavor', 'just', 'taste', 'great', 'good', 'like', 'coffee', 'br']\n",
            "\n",
            "\n",
            "Top 10 words for topic #2\n",
            "['orange', 'switch', 'ingredients', 'soda', 'dogs', 'juice', 'food', 'treats', 'dog', 'br']\n",
            "\n",
            "\n",
            "Top 10 words for topic #3\n",
            "['bitter', 'smooth', 'strong', 'keurig', 'blend', 'roast', 'bold', 'cup', 'br', 'coffee']\n",
            "\n",
            "\n",
            "Top 10 words for topic #4\n",
            "['black', 'br', 'iced', 'drink', 'loose', 'earl', 'grey', 'teas', 'green', 'tea']\n",
            "\n",
            "\n",
            "Top 10 words for topic #5\n",
            "['newman', 'cat', 'treat', 'loves', 'coffee', 'tea', 'dogs', 'food', 'treats', 'dog']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (c) \n",
        "Apply non-negative matrix factorization using five components. Print the ten strongest words for each of the topics."
      ],
      "metadata": {
        "id": "mIR2XplKHiCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NMF\n",
        "nmf = NMF(n_components = 5)\n",
        "nmf_fit = nmf.fit_transform(revs_tfidf)\n",
        "\n",
        "# strongest words for 10 topics\n",
        "for i, topic in enumerate(nmf.components_):\n",
        "\n",
        "    first_topic_nmf = nmf.components_[i]\n",
        "    top_topic_words_nmf = first_topic_nmf.argsort()[-10:]\n",
        "\n",
        "    print(\"Top 10 words for topic #{}\".format(i + 1))\n",
        "    print([tfidf.get_feature_names_out()[i] for i in top_topic_words_nmf])\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKKT7tqmH0gt",
        "outputId": "2dc61919-f508-453e-e708-d5db14e2a132"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 words for topic #1\n",
            "['chocolate', 'really', 'love', 'flavor', 'just', 'product', 'taste', 'good', 'great', 'like']\n",
            "\n",
            "\n",
            "Top 10 words for topic #2\n",
            "['bitter', 'like', 'keurig', 'roast', 'flavor', 'blend', 'bold', 'strong', 'cup', 'coffee']\n",
            "\n",
            "\n",
            "Top 10 words for topic #3\n",
            "['100', 'water', 'orange', 'http', 'switch', 'soda', 'drink', 'sugar', 'juice', 'br']\n",
            "\n",
            "\n",
            "Top 10 words for topic #4\n",
            "['bags', 'flavor', 'drink', 'iced', 'earl', 'loose', 'grey', 'teas', 'green', 'tea']\n",
            "\n",
            "\n",
            "Top 10 words for topic #5\n",
            "['old', 'love', 'cat', 'eat', 'treat', 'loves', 'dogs', 'food', 'treats', 'dog']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (d) \n",
        "Apply Latent Dirichlet Allocation (LDA) using five topics. Print the ten strongest words for each of the topics.\n"
      ],
      "metadata": {
        "id": "XeAQDUPdIwAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code based off of: https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0\n",
        "\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        # deacc=True removes punctuations\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "\n",
        "data = Reviews.clean_Text.values.tolist()\n",
        "data_words = list(sent_to_words(data))\n",
        "print(data_words[:1][0][:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05Giwx_jNf7N",
        "outputId": "feb61dd9-d5e8-4e27-b9c4-1fee20a6e792"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['have', 'bought', 'several', 'of', 'the', 'vitality', 'canned', 'dog', 'food', 'products', 'and', 'have', 'found', 'them', 'all', 'to', 'be', 'of', 'good', 'quality', 'the', 'product', 'looks', 'more', 'like', 'stew', 'than', 'processed', 'meat', 'and']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.corpora as corpora\n",
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_words)\n",
        "# Create Corpus\n",
        "texts = data_words\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]"
      ],
      "metadata": {
        "id": "BNjlgalpPOMc"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code based off of: https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0\n",
        "\n",
        "from pprint import pprint\n",
        "import gensim\n",
        "# number of topics\n",
        "num_topics = 5\n",
        "# Build LDA model\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=num_topics)\n",
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3RNI9rUNDW8",
        "outputId": "a69d9b7b-2868-44a8-e628-e984320c7c73"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.042*\"the\" + 0.035*\"and\" + 0.025*\"is\" + 0.024*\"to\" + 0.024*\"it\" + '\n",
            "  '0.021*\"this\" + 0.015*\"of\" + 0.012*\"br\" + 0.012*\"have\" + 0.012*\"with\"'),\n",
            " (1,\n",
            "  '0.051*\"the\" + 0.028*\"and\" + 0.026*\"br\" + 0.025*\"to\" + 0.020*\"of\" + '\n",
            "  '0.015*\"it\" + 0.014*\"in\" + 0.014*\"they\" + 0.013*\"for\" + 0.012*\"my\"'),\n",
            " (2,\n",
            "  '0.031*\"it\" + 0.030*\"coffee\" + 0.029*\"this\" + 0.027*\"is\" + 0.027*\"the\" + '\n",
            "  '0.022*\"and\" + 0.021*\"tea\" + 0.019*\"to\" + 0.014*\"of\" + 0.014*\"not\"'),\n",
            " (3,\n",
            "  '0.042*\"the\" + 0.038*\"it\" + 0.034*\"and\" + 0.024*\"to\" + 0.023*\"is\" + '\n",
            "  '0.023*\"of\" + 0.018*\"this\" + 0.015*\"in\" + 0.014*\"for\" + 0.011*\"that\"'),\n",
            " (4,\n",
            "  '0.043*\"the\" + 0.027*\"and\" + 0.024*\"to\" + 0.022*\"it\" + 0.020*\"for\" + '\n",
            "  '0.019*\"this\" + 0.016*\"of\" + 0.013*\"is\" + 0.013*\"you\" + 0.012*\"my\"')]\n"
          ]
        }
      ]
    }
  ]
}