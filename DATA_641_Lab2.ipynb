{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Pb4mrxijzlA"
   },
   "source": [
    "# DATA-641: Lab 2\n",
    "\n",
    "Max Calzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xi8MwzConrQL"
   },
   "source": [
    "## 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VOUrYLGXkO_4",
    "outputId": "2497cc08-8f74-4777-fe87-698a968f8336"
   },
   "outputs": [],
   "source": [
    "# !pip install BackTranslation\n",
    "from BackTranslation import BackTranslation\n",
    "\n",
    "# Code based off of: https://pypi.org/project/BackTranslation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m0ezimaekUCX",
    "outputId": "7d123fd5-9802-4e77-9d51-93160955afc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is something that I never told you.\n"
     ]
    }
   ],
   "source": [
    "# Spanish\n",
    "trans = BackTranslation(url=[\n",
    "      'translate.google.com',\n",
    "      'translate.google.es',\n",
    "    ])\n",
    "result = trans.translate('Theres something I never told you.', src='en', tmp = 'es')\n",
    "print(result.result_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbQiSyjCmn5G",
    "outputId": "cc753d8b-5974-48e5-c912-f8fc27686c8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is something I never told you.\n"
     ]
    }
   ],
   "source": [
    "# Greek\n",
    "trans = BackTranslation(url=[\n",
    "      'translate.google.com',\n",
    "      'translate.google.gr',\n",
    "    ])\n",
    "result = trans.translate('Theres something I never told you.', src='en', tmp = 'el')\n",
    "print(result.result_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qgyK_uESoEXU",
    "outputId": "ecf0b3cd-e595-49b4-c30e-135831225f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is something I never told you.\n"
     ]
    }
   ],
   "source": [
    "# French\n",
    "\n",
    "trans = BackTranslation(url=[\n",
    "      'translate.google.com',\n",
    "      'translate.google.fr',\n",
    "    ])\n",
    "result = trans.translate('Theres something I never told you.', src='en', tmp = 'fr')\n",
    "print(result.result_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsdHPxCPpYk7"
   },
   "source": [
    "## 2)\n",
    "\n",
    "### 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ALgA4qdOpcJF",
    "outputId": "4b2b1b07-b970-468e-ea28-8d37cf97b20f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>python - How do I get the current time? - Stack Overflow</title>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code based off of: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import ssl\n",
    "ssl.create_default_https_context = ssl._create_unverified_context # you need a certificate\n",
    "myurl = \"https://stackoverflow.com/questions/415511/how-do-i-get-the-current-time\"\n",
    "html = urlopen(myurl).read()\n",
    "soupified = BeautifulSoup(html, \"html.parser\")\n",
    "soupified.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NcwrzX8NtPZg",
    "outputId": "5b187be3-7b38-4019-fad1-74c44d17e019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"s-prose js-post-body\" itemprop=\"text\">\n",
      "<p>How do I get the current time?</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "question = soupified.find(\"div\", {\"class\":\"question\"})\n",
    "questiontext = question.find(\"div\", {\"class\":\"s-prose js-post-body\"})\n",
    "# print(questiontext.get_text().strip())\n",
    "print(questiontext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZ8-IyruOA3Z",
    "outputId": "3e3e9f54-463a-44b4-cfe5-7f3a65bac87f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use datetime:\n",
      ">>> import datetime\n",
      ">>> now = datetime.datetime.now()\n",
      ">>> now\n",
      "datetime.datetime(2009, 1, 6, 15, 8, 24, 78915)\n",
      ">>> print(now)\n",
      "2009-01-06 15:08:24.789150\n",
      "\n",
      "For just the clock time without the date:\n",
      ">>> now.time()\n",
      "datetime.time(15, 8, 24, 78915)\n",
      ">>> print(now.time())\n",
      "15:08:24.789150\n",
      "\n",
      "\n",
      "To save typing, you can import the datetime object from the datetime module:\n",
      ">>> from datetime import datetime\n",
      "\n",
      "Then remove the prefix datetime. from all of the above.\n"
     ]
    }
   ],
   "source": [
    "answer = soupified.find(\"div\", {\"class\":\"answer js-answer accepted-answer js-accepted-answer\"})\n",
    "answertext = answer.find(\"div\", {\"class\":\"s-prose js-post-body\"})\n",
    "print(answertext.get_text().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8msWVnoetWX1"
   },
   "source": [
    "## 2b ??????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gWjTQ6YwfnRi"
   },
   "outputs": [],
   "source": [
    "# Also downloads an empty sheet\n",
    "\n",
    "# https://www.geeksforgeeks.org/downloading-files-web-using-python/\n",
    "\n",
    "# imported the requests library\n",
    "import requests\n",
    "url = \"https://zoisboukouvalas.github.io/COVID19_Twitter_Dataset.xlsx\"\n",
    "\n",
    "# URL of the image to be downloaded is defined as image_url\n",
    "r = requests.get(url) # create HTTP response object\n",
    "\n",
    "# send a HTTP request to the server and save\n",
    "# the HTTP response in a response object called r\n",
    "with open(\"COVID19_Twitter_Dataset.xlsx\",'wb') as f:\n",
    "\n",
    "\t# Saving received content as an xlsx file in\n",
    "\t# binary format\n",
    "\n",
    "\t# write the contents of the response (r.content)\n",
    "\t# to a new file in binary mode.\n",
    "\tf.write(r.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "-UVphTTdeIb0"
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1GP9ITtweHWp",
    "outputId": "9e47cca9-68eb-4631-97da-e01aa254fabe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57191"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloads an empty sheet\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://zoisboukouvalas.github.io/COVID19_Twitter_Dataset.xlsx'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "\n",
    "open('covid19.xlsx', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5tZqWTItXxe"
   },
   "outputs": [],
   "source": [
    "https://zoisboukouvalas.github.io/COVID19_Twitter_Dataset.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EI8teshyaMZr",
    "outputId": "d121aed0-94c6-47eb-9d94-222a87dea6d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57191"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://zoisboukouvalas.github.io/COVID19_Twitter_Dataset.xlsx\"\n",
    "response = requests.get(url)\n",
    "open(\"content\", \"wb\").write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "5dA9gK1GcFyk",
    "outputId": "dcfe35f3-53eb-46ae-851d-618a1f32dc54"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "qUTioOalab3V"
   },
   "outputs": [],
   "source": [
    "# !pip install wget\n",
    "# import wget\n",
    "# myurl = input(\"https://zoisboukouvalas.github.io/COVID19_Twitter_Dataset.xlsx\")\n",
    "# wget.download(myurl , '/content')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiXdB4MZzB9R"
   },
   "source": [
    "## 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0iEiNHcN5PGL",
    "outputId": "3d12afb8-c1d7-4cd3-ee0e-389fd457c6e2"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3763229622.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/04/tr_5ywbd11s45c32j2wwzh2r0000gn/T/ipykernel_37356/3763229622.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    pip install PyPDF2\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# !pip install PyPDF2\n",
    "# pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "haMkOILTG5OO",
    "outputId": "e7c4232f-3c80-4d01-8502-9987025e9d3c"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PyPDF2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/04/tr_5ywbd11s45c32j2wwzh2r0000gn/T/ipykernel_37356/1027934533.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Code based off of: https://stackoverflow.com/questions/34837707/how-to-extract-text-from-a-pdf-file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPyPDF2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPdfReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPdfReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sample.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PyPDF2'"
     ]
    }
   ],
   "source": [
    "# Code based off of: https://stackoverflow.com/questions/34837707/how-to-extract-text-from-a-pdf-file\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "reader = PdfReader(\"sample.pdf\")\n",
    "text = \"\"\n",
    "for page in reader.pages:\n",
    "    text += page.extract_text() + \"\\n\"\n",
    "\n",
    "print(text)\n",
    "\n",
    "# # https://pypi.org/project/PyPDF2/\n",
    "\n",
    "# import PyPDF2\n",
    "\n",
    "# from PyPDF2 import PdfReader\n",
    "\n",
    "# reader = PdfReader('sample.pdf') # cannot read an empty file\n",
    "# # reader = PdfReader('DATA_441_641_hwk1-1.pdf') # this actually prints the text\n",
    "# number_of_pages = len(reader.pages)\n",
    "# page = reader.pages[0]\n",
    "# text = page.extract_text()\n",
    "\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMUYun6K7VxO"
   },
   "source": [
    "## 4)\n",
    "\n",
    "### 4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFvNNxRV7UYO",
    "outputId": "7c8fd197-118f-4147-8ea9-e5038b95b9de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "need to finalize the demo corpus which will be used for this notebook & should be done soon!!. it should be done by the ending of this month. but will it? this notekook has been run 4 times!!\n"
     ]
    }
   ],
   "source": [
    "corpus = 'Need to finalize the demo corpus which will be used for this notebook & should be done soon!!. It should be done by the ending of this month. But will it? This notekook has been run 4 times!!'\n",
    "corpus = corpus.lower()\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvIkDqqjDDbi"
   },
   "source": [
    "### 4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "5jwXFbCqDFRP",
    "outputId": "73aa2d73-fd8b-4822-ff53-ceb80ac778b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'need to finalize the demo corpus which will be used for this notebook & should be done soon!!. it should be done by the ending of this month. but will it? this notekook has been run  times!!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "corpus = re.sub(r'\\d+','',corpus)\n",
    "corpus\n",
    "\n",
    "# `4` was removed, and not replaced with `four`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mS-n23aDbbV"
   },
   "source": [
    "### 4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLqwX4S-Ddt5",
    "outputId": "ee13537b-9746-4cbf-c458-1bbdf66ea38b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NLTK\n",
      "Tokenized corpus: ['need', 'to', 'finalize', 'the', 'demo', 'corpus', 'which', 'will', 'be', 'used', 'for', 'this', 'notebook', '&', 'should', 'be', 'done', 'soon', '!', '!', '.', 'it', 'should', 'be', 'done', 'by', 'the', 'ending', 'of', 'this', 'month', '.', 'but', 'will', 'it', '?', 'this', 'notekook', 'has', 'been', 'run', 'times', '!', '!']\n",
      "Tokenized corpus without stopwords: ['need', 'finalize', 'demo', 'corpus', 'used', 'notebook', '&', 'done', 'soon', '!', '!', '.', 'done', 'ending', 'month', '.', '?', 'notekook', 'run', 'times', '!', '!']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/maxcalzada/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/maxcalzada/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words_nltk = set(stopwords.words('english'))\n",
    "\n",
    "tokenized_corpus_nltk = word_tokenize(corpus)\n",
    "print(\"\\nNLTK\\nTokenized corpus:\",tokenized_corpus_nltk)\n",
    "\n",
    "tokenized_corpus_without_stopwords = [i for i in tokenized_corpus_nltk if not i in stop_words_nltk]\n",
    "print(\"Tokenized corpus without stopwords:\",tokenized_corpus_without_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-sttS5mFQ0L"
   },
   "source": [
    "### 4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OjO_9dcPLBt5",
    "outputId": "42b3ae3b-1639-49d2-a1db-8858ab058cc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Stemming:\n",
      "need final demo corpu use notebook & done soon ! ! . done end month . ? notekook run time ! ! "
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "stemmer= PorterStemmer()\n",
    "\n",
    "# print(\"Before Stemming:\")\n",
    "# print(corpus)\n",
    "\n",
    "print(\"After Stemming:\")\n",
    "for word in tokenized_corpus_without_stopwords:\n",
    "    print(stemmer.stem(word),end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPWfk9OXLPm8"
   },
   "source": [
    "### 4e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9SAZ8KP0LPRn",
    "outputId": "d7c3c870-985a-4ebb-ee64-4ed8eac114e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/maxcalzada/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/maxcalzada/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "need finalize demo corpus used notebook & done soon ! ! . done ending month . ? notekook run time ! ! "
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "\n",
    "for word in tokenized_corpus_without_stopwords:\n",
    "    print(lemmatizer.lemmatize(word),end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
